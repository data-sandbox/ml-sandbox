{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Sentiment Analysis\n",
    "\n",
    "This project aims to experiment with machine learning text classification models for [Amazon reviews](https://huggingface.co/datasets/amazon_polarity). The goal of this sentiment analysis is to identify whether a review is positive or negative based on the text alone.\n",
    "\n",
    "References:\n",
    "- [Hugging Face: \"Getting Started with Sentiment Analysis using Python\"](https://huggingface.co/blog/sentiment-analysis-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_polarity (/Users/user/.cache/huggingface/datasets/amazon_polarity/amazon_polarity/3.0.0/a27b32b7e7b88eb274a8fa8ba0f654f1fe998a87c22547557317793b5d2772dc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0b3109bd404c509fa5bfd3074514fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download dataset from Hugging Face\n",
    "dataset = load_dataset(\"amazon_polarity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train'].to_pandas()\n",
    "test = dataset['test'].to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (3600000, 3)\n",
      "Test set: (400000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: {train.shape}')\n",
    "print(f'Test set: {test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3600000 entries, 0 to 3599999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   label    int64 \n",
      " 1   title    object\n",
      " 2   content  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 82.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Stuning even for the non-gamer</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazing!</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent Soundtrack</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title   \n",
       "0      1                     Stuning even for the non-gamer  \\\n",
       "1      1              The best soundtrack ever to anything.   \n",
       "2      1                                           Amazing!   \n",
       "3      1                               Excellent Soundtrack   \n",
       "4      1  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                             content  \n",
       "0  This sound track was beautiful! It paints the ...  \n",
       "1  I'm reading a lot of reviews saying that this ...  \n",
       "2  This soundtrack is my favorite music of all ti...  \n",
       "3  I truly like this soundtrack and I enjoy video...  \n",
       "4  If you've played the game, you know how divine...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple Naive Bayes classifier as the baseline. Because of the size of the dataset, we'll also create smaller sets for faster training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_train = train['content']\n",
    "y_train = train['label']\n",
    "\n",
    "X_test = test['content']\n",
    "y_test = test['label']\n",
    "\n",
    "# Smaller datasets for faster training and testing initially\n",
    "X_train_small = X_train[:len(X_train)//20]\n",
    "y_train_small = y_train[:len(X_train)//20]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `TfidfVectorizer` to vectorize the individual words and re-weight the counts based on the inverse-document frequency (penalizing common words that appear frequently such as \"the\", \"a\", \"is\" etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83    200000\n",
      "           1       0.84      0.78      0.81    200000\n",
      "\n",
      "    accuracy                           0.82    400000\n",
      "   macro avg       0.82      0.82      0.82    400000\n",
      "weighted avg       0.82      0.82      0.82    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_pipe = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                    ('classifier', MultinomialNB())])\n",
    "\n",
    "nb_pipe.fit(X_train_small, y_train_small)\n",
    "print(classification_report(y_test, nb_pipe.predict(X_test)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll add a layer of complexity by including bigrams and stopwords in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85    200000\n",
      "           1       0.85      0.84      0.84    200000\n",
      "\n",
      "    accuracy                           0.85    400000\n",
      "   macro avg       0.85      0.85      0.85    400000\n",
      "weighted avg       0.85      0.85      0.85    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner', 'textcat'])\n",
    "\n",
    "STOP_WORDS = STOP_WORDS.union({'ll', 've'})\n",
    "\n",
    "nb_pipe = Pipeline([('vectorizer', TfidfVectorizer(ngram_range=(1, 2),\n",
    "                                                   stop_words=list(STOP_WORDS))),\n",
    "                    ('classifier', MultinomialNB())])\n",
    "\n",
    "nb_pipe.fit(X_train_small, y_train_small)\n",
    "print(classification_report(y_test, nb_pipe.predict(X_test)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams and stopwords have indeed improved the model performance. Let's try a more complicated machine learning algorithm next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84    200000\n",
      "           1       0.85      0.84      0.84    200000\n",
      "\n",
      "    accuracy                           0.84    400000\n",
      "   macro avg       0.84      0.84      0.84    400000\n",
      "weighted avg       0.84      0.84      0.84    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_pipe = Pipeline([('vectorizer', TfidfVectorizer(ngram_range=(1, 2),\n",
    "                                                    stop_words=list(STOP_WORDS))),\n",
    "                     ('classifier', SGDClassifier(max_iter=50))])\n",
    "\n",
    "sgd_pipe.fit(X_train_small, y_train_small)\n",
    "print(classification_report(y_test, sgd_pipe.predict(X_test)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SGDClassifier` seems to perform worse than the `MultinomialNB` model. Let's try GridSearch to find more optimal hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87    200000\n",
      "           1       0.87      0.88      0.87    200000\n",
      "\n",
      "    accuracy                           0.87    400000\n",
      "   macro avg       0.87      0.87      0.87    400000\n",
      "weighted avg       0.87      0.87      0.87    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'classifier__alpha': (0.001, 0.0001, 0.00001),\n",
    "          # TODO 'classifier__loss': ('log_loss', 'hinge'), # log_loss = Logistic Regression, hinge = Linear SVM\n",
    "          }\n",
    "\n",
    "sgd_grid = GridSearchCV(sgd_pipe, params, cv=3, verbose=True)\n",
    "sgd_grid.fit(X_train_small, y_train_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87    200000\n",
      "           1       0.87      0.88      0.87    200000\n",
      "\n",
      "    accuracy                           0.87    400000\n",
      "   macro avg       0.87      0.87      0.87    400000\n",
      "weighted avg       0.87      0.87      0.87    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, sgd_grid.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 1e-05}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_grid.best_params_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quick GridSearch exercise has further improved the model as expected. Future work will be to increase the range of alphas and compare Logistic Regression versus SVM within SGD, but for now we'll continue with fast exploration iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
